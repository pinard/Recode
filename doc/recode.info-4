This is recode.info, produced by makeinfo version 4.0 from recode.texi.

INFO-DIR-SECTION Internationalization and character sets
START-INFO-DIR-ENTRY
* recode: (recode).     Conversion between character sets and surfaces.
END-INFO-DIR-ENTRY

   This file documents the `recode' command, which has the purpose of
converting files between various character sets and surfaces.

   Copyright (C) 1990, 93, 94, 96, 97, 98, 99, 00 Free Software
Foundation, Inc.

   Permission is granted to make and distribute verbatim copies of this
manual provided the copyright notice and this permission notice are
preserved on all copies.

   Permission is granted to copy and distribute modified versions of
this manual under the conditions for verbatim copying, provided that
the entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

   Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be stated in a
translation approved by the Foundation.


File: recode.info,  Node: ASCII-BS,  Next: flat,  Prev: ISO 8859,  Up: ASCII misc

ASCII 7-bits, `BS' to overstrike
================================

   This charset is available in `recode' under the name `ASCII-BS',
with `BS' as an acceptable alias.

   The file is straight ASCII, seven bits only.  According to the
definition of ASCII, diacritics are applied by a sequence of three
characters: the letter, one `BS', the diacritic mark.  We deviate
slightly from this by exchanging the diacritic mark and the letter so,
on a screen device, the diacritic will disappear and let the letter
alone.  At recognition time, both methods are acceptable.

   The French quotes are coded by the sequences: `< BS "' or `" BS <'
for the opening quote and `> BS "' or `" BS >' for the closing quote.
This artificial convention was inherited in straight `ASCII-BS' from
habits around `Bang-Bang' entry, and is not well known.  But we decided
to stick to it so that `ASCII-BS' charset will not lose French quotes.

   The `ASCII-BS' charset is independent of `ASCII', and different.
The following examples demonstrate this, knowing at advance that `!2'
is the `Bang-Bang' way of representing an `e' with an acute accent.
Compare:

     % echo \!2 | recode -v bang..l1/d
     Request: Bang-Bang..ISO-8859-1/Decimal-1
     233,  10

with:

     % echo \!2 | recode -v bang..bs/d
     Request: Bang-Bang..ISO-8859-1..ASCII-BS/Decimal-1
      39,   8, 101,  10

   In the first case, the `e' with an acute accent is merely
transmitted by the `Latin-1..ASCII' mapping, not having a special
recoding rule for it.  In the `Latin-1..ASCII-BS' case, the acute
accent is applied over the `e' with a backspace: diacriticised
characters have special rules.  For the `ASCII-BS' charset,
reversibility is still possible, but there might be difficult cases.


File: recode.info,  Node: flat,  Prev: ASCII-BS,  Up: ASCII misc

ASCII without diacritics nor underline
======================================

   This charset is available in `recode' under the name `flat'.

   This code is ASCII expunged of all diacritics and underlines, as
long as they are applied using three character sequences, with `BS' in
the middle.  Also, despite slightly unrelated, each control character is
represented by a sequence of two or three graphic characters.  The
newline character, however, keeps its functionality and is not
represented.

   Note that charset `flat' is a terminal charset.  We can convert _to_
`flat', but not _from_ it.


File: recode.info,  Node: IBM and MS,  Next: CDC,  Prev: ASCII misc,  Up: Top

Some IBM or Microsoft charsets
******************************

   The `recode' program provides various IBM or Microsoft code pages
(*note Tabular::).  An easy way to find them all at once out of the
`recode' program itself is through the command:

     recode -l | egrep -i '(CP|IBM)[0-9]'

But also, see few special charsets presented in the incoming sections.

* Menu:

* EBCDIC::              EBCDIC codes
* IBM-PC::              IBM's PC code
* Icon-QNX::            Unisys' Icon code


File: recode.info,  Node: EBCDIC,  Next: IBM-PC,  Prev: IBM and MS,  Up: IBM and MS

EBCDIC code
===========

   This charset is the IBM's External Binary Coded Decimal for
Interchange Coding.  This is an eight bits code.  The following three
variants were implemented in `recode' independently of RFC 1345:

`EBCDIC'
     In `recode', the `us..ebcdic' conversion is identical to `dd
     conv=ebcdic' conversion, and `recode' `ebcdic..us' conversion is
     identical to `dd conv=ascii' conversion.  This charset also
     represents the way Control Data Corporation relates EBCDIC to
     8-bits ASCII.

`EBCDIC-CCC'
     In `recode', the `us..ebcdic-ccc' or `ebcdic-ccc..us' conversions
     represent the way Concurrent Computer Corporation (formerly Perkin
     Elmer) relates EBCDIC to 8-bits ASCII.

`EBCDIC-IBM'
     In `recode', the `us..ebcdic-ibm' conversion is _almost_ identical
     to the GNU `dd conv=ibm' conversion.  Given the exact `dd
     conv=ibm' conversion table, `recode' once said:

          Codes  91 and 213 both recode to 173
          Codes  93 and 229 both recode to 189
          No character recodes to  74
          No character recodes to 106

     So I arbitrarily chose to recode 213 by 74 and 229 by 106.  This
     makes the `EBCDIC-IBM' recoding reversible, but this is not
     necessarily the best correction.  In any case, I think that GNU
     `dd' should be amended.  `dd' and `recode' should ideally agree on
     the same correction.  So, this table might change once again.

   RFC 1345 brings into `recode' 15 other EBCDIC charsets, and 21 other
charsets having EBCDIC in at least one of their alias names.  You can
get a list of all these by executing:

     recode -l | grep -i ebcdic

   Note that `recode' may convert a pure stream of EBCDIC characters,
but it does not know how to handle binary data between records which is
sometimes used to delimit them and build physical blocks.  If end of
lines are not marked, fixed record size may produce something readable,
but `VB' or `VBS' blocking is likely to yield some garbage in the
converted results.


File: recode.info,  Node: IBM-PC,  Next: Icon-QNX,  Prev: EBCDIC,  Up: IBM and MS

IBM's PC code
=============

   This charset is available in `recode' under the name `IBM-PC', with
`dos', `MSDOS' and `pc' as acceptable aliases.  The shortest way of
specifying it in `recode' is `pc'.

   The charset is aimed towards a PC microcomputer from IBM or any
compatible.  This is an eight-bit code.  This charset is fairly old in
`recode', its tables were produced a long while ago by mere inspection
of a printed chart of the IBM-PC codes and glyph.

   It has `CR-LF' as its implied surface.  This means that, if the
original end of lines have to be preserved while going out of `IBM-PC',
they should currently be added back through the usage of a surface on
the other charset, or better, just never removed.  Here are examples
for both cases:

     recode pc..l2/cl < INPUT > OUTPUT
     recode pc/..l2 < INPUT > OUTPUT

   RFC 1345 brings into `recode' 44 `IBM' charsets or code pages, and
also 8 other code pages.  You can get a list of these all these by
executing:(1)

     recode -l | egrep -i '(CP|IBM)[0-9]'

All charset or aliases beginning with letters `CP' or `IBM' also have
`CR-LF' as their implied surface.  The same is true for a purely
numeric alias in the same family.  For example, all of `819', `CP819'
and `IBM819' imply `CR-LF' as a surface.  Note that `ISO-8859-1' does
_not_ imply a surface, despite it shares the same tabular data as `819'.

   There are a few discrepancies between this `IBM-PC' charset and the
very similar RFC 1345 charset `ibm437', which have not been analysed
yet, so the charsets are being kept separate for now.  This might
change in the future, and the `IBM-PC' charset might disappear.
Wizards would be interested in comparing the output of these two
commands:

     recode -vh IBM-PC..Latin-1
     recode -vh IBM437..Latin-1

The first command uses the charset prior to RFC 1345 introduction.
Both methods give different recodings.  These differences are annoying,
the fuzziness will have to be explained and settle down one day.

   ---------- Footnotes ----------

   (1) On DOS/Windows, stock shells do not know that apostrophes quote
special characters like `|', so one need to use double quotes instead
of apostrophes.


File: recode.info,  Node: Icon-QNX,  Prev: IBM-PC,  Up: IBM and MS

Unisys' Icon code
=================

   This charset is available in `recode' under the name `Icon-QNX',
with `QNX' as an acceptable alias.

   The file is using Unisys' Icon way to represent diacritics with code
25 escape sequences, under the system QNX.  This is a seven-bit code,
even if eight-bit codes can flow through as part of IBM-PC charset.


File: recode.info,  Node: CDC,  Next: Micros,  Prev: IBM and MS,  Up: Top

Charsets for CDC machines
*************************

   What is now `recode' evolved out, through many transformations
really, from a set of programs which were originally written in
"COMPASS", Control Data Corporation's assembler, with bits in FORTRAN,
and later rewritten in CDC 6000 Pascal.  The CDC heritage shows by the
fact some old CDC charsets are still supported.

   The `recode' author used to be familiar with CDC Scope-NOS/BE and
Kronos-NOS, and many CDC formats.  Reading CDC tapes directly on other
machines is often a challenge, and `recode' does not always solve it.
It helps having tapes created in coded mode instead of binary mode, and
using `S' (Stranger) tapes instead of `I' (Internal) tapes.  ANSI
labels and multi-file tapes might be the source of trouble.  There are
ways to handle a few Cyber Record Manager formats, but some of them
might be quite difficult to decode properly after the transfer is done.

   The `recode' program is usable only for a small subset of NOS text
formats, and surely not with binary textual formats, like `UPDATE' or
`MODIFY' sources, for example.  `recode' is not especially suited for
reading 8/12 or 56/60 packing, yet this could easily arranged if there
was a demand for it.  It does not have the ability to translate Display
Code directly, as the ASCII conversion implied by tape drivers or FTP
does the initial approximation.  `recode' can decode 6/12 caret
notation over Display Code already mapped to ASCII.

* Menu:

* Display Code::        Control Data's Display Code
* CDC-NOS::             ASCII 6/12 from NOS
* Bang-Bang::           ASCII ``bang bang''


File: recode.info,  Node: Display Code,  Next: CDC-NOS,  Prev: CDC,  Up: CDC

Control Data's Display Code
===========================

   This code is not available in `recode', but repeated here for
reference.  This is a 6-bit code used on CDC mainframes.

     Octal display code to graphic       Octal display code to octal ASCII
     
     00  :    20  P    40  5   60  #     00 072  20 120  40 065  60 043
     01  A    21  Q    41  6   61  [     01 101  21 121  41 066  61 133
     02  B    22  R    42  7   62  ]     02 102  22 122  42 067  62 135
     03  C    23  S    43  8   63  %     03 103  23 123  43 070  63 045
     04  D    24  T    44  9   64  "     04 104  24 124  44 071  64 042
     05  E    25  U    45  +   65  _     05 105  25 125  45 053  65 137
     06  F    26  V    46  -   66  !     06 106  26 126  46 055  66 041
     07  G    27  W    47  *   67  &     07 107  27 127  47 052  67 046
     10  H    30  X    50  /   70  '     10 110  30 130  50 057  70 047
     11  I    31  Y    51  (   71  ?     11 111  31 131  51 050  71 077
     12  J    32  Z    52  )   72  <     12 112  32 132  52 051  72 074
     13  K    33  0    53  $   73  >     13 113  33 060  53 044  73 076
     14  L    34  1    54  =   74  @     14 114  34 061  54 075  74 100
     15  M    35  2    55      75  \     15 115  35 062  55 040  75 134
     16  N    36  3    56  ,   76  ^     16 116  36 063  56 054  76 136
     17  O    37  4    57  .   77  ;     17 117  37 064  57 056  77 073

   In older times, `:' used octal 63, and octal 0 was not a character.
The table above shows the ASCII glyph interpretation of codes 60 to 77,
yet these 16 codes were once defined differently.

   There is no explicit end of line in Display Code, and the Cyber
Record Manager introduced many new ways to represent them, the
traditional end of lines being reachable by setting `RT' to `Z'.  If
6-bit bytes in a file are sequentially counted from 1, a traditional
end of line does exist if bytes 10*N+9 and 10N+10 are both zero for a
given N, in which case these two bytes are not to be interpreted as
`::'.  Also, up to 9 immediately preceeding zero bytes, going backward,
are to be considered as part of the end of line and not interpreted as
`:'(1).

   ---------- Footnotes ----------

   (1) This convention replaced an older one saying that up to 4
immediately preceeding _pairs_ of zero bytes, going backward, are to be
considered as part of the end of line and not interpreted as `::'.


File: recode.info,  Node: CDC-NOS,  Next: Bang-Bang,  Prev: Display Code,  Up: CDC

ASCII 6/12 from NOS
===================

   This charset is available in `recode' under the name `CDC-NOS', with
`NOS' as an acceptable alias.

   This is one of the charsets in use on CDC Cyber NOS systems to
represent ASCII, sometimes named "NOS 6/12" code for coding ASCII.
This code is also known as "caret ASCII".  It is based on a six bits
character set in which small letters and control characters are coded
using a `^' escape and, sometimes, a `@' escape.

   The routines given here presume that the six bits code is already
expressed in ASCII by the communication channel, with embedded ASCII
`^' and `@' escapes.

   Here is a table showing which characters are being used to encode
each ASCII character.

     000  ^5  020  ^#  040     060  0  100 @A  120  P  140  @G  160  ^P
     001  ^6  021  ^[  041  !  061  1  101  A  121  Q  141  ^A  161  ^Q
     002  ^7  022  ^]  042  "  062  2  102  B  122  R  142  ^B  162  ^R
     003  ^8  023  ^%  043  #  063  3  103  C  123  S  143  ^C  163  ^S
     004  ^9  024  ^"  044  $  064  4  104  D  124  T  144  ^D  164  ^T
     005  ^+  025  ^_  045  %  065  5  105  E  125  U  145  ^E  165  ^U
     006  ^-  026  ^!  046  &  066  6  106  F  126  V  146  ^F  166  ^V
     007  ^*  027  ^&  047  '  067  7  107  G  127  W  147  ^G  167  ^W
     010  ^/  030  ^'  050  (  070  8  110  H  130  X  150  ^H  170  ^X
     011  ^(  031  ^?  051  )  071  9  111  I  131  Y  151  ^I  171  ^Y
     012  ^)  032  ^<  052  *  072 @D  112  J  132  Z  152  ^J  172  ^Z
     013  ^$  033  ^>  053  +  073  ;  113  K  133  [  153  ^K  173  ^0
     014  ^=  034  ^@  054  ,  074  <  114  L  134  \  154  ^L  174  ^1
     015  ^   035  ^\  055  -  075  =  115  M  135  ]  155  ^M  175  ^2
     016  ^,  036  ^^  056  .  076  >  116  N  136 @B  156  ^N  176  ^3
     017  ^.  037  ^;  057  /  077  ?  117  O  137  _  157  ^O  177  ^4


File: recode.info,  Node: Bang-Bang,  Prev: CDC-NOS,  Up: CDC

ASCII "bang bang"
=================

   This charset is available in `recode' under the name `Bang-Bang'.

   This code, in use on Cybers at Universite' de Montre'al mainly,
served to code a lot of French texts.  The original name of this
charset is "ASCII code' Display".  This code is also known as
"Bang-bang".  It is based on a six bits character set in which
capitals, French diacritics and a few others are coded using an `!'
escape followed by a single character, and control characters using a
double `!' escape followed by a single character.

   The routines given here presume that the six bits code is already
expressed in ASCII by the communication channel, with embedded ASCII `!'
escapes.

   Here is a table showing which characters are being used to encode
each ASCII character.

     000 !!@  020 !!P  040    060 0  100 @   120 !P  140 !@ 160 P
     001 !!A  021 !!Q  041 !" 061 1  101 !A  121 !Q  141 A  161 Q
     002 !!B  022 !!R  042 "  062 2  102 !B  122 !R  142 B  162 R
     003 !!C  023 !!S  043 #  063 3  103 !C  123 !S  143 C  163 S
     004 !!D  024 !!T  044 $  064 4  104 !D  124 !T  144 D  164 T
     005 !!E  025 !!U  045 %  065 5  105 !E  125 !U  145 E  165 U
     006 !!F  026 !!V  046 &  066 6  106 !F  126 !V  146 F  166 V
     007 !!G  027 !!W  047 '  067 7  107 !G  127 !W  147 G  167 W
     010 !!H  030 !!X  050 (  070 8  110 !H  130 !X  150 H  170 X
     011 !!I  031 !!Y  051 )  071 9  111 !I  131 !Y  151 I  171 Y
     012 !!J  032 !!Z  052 *  072 :  112 !J  132 !Z  152 J  172 Z
     013 !!K  033 !![  053 +  073 ;  113 !K  133 [   153 K  173 ![
     014 !!L  034 !!\  054 ,  074 <  114 !L  134 \   154 L  174 !\
     015 !!M  035 !!]  055 -  075 =  115 !M  135 ]   155 M  175 !]
     016 !!N  036 !!^  056 .  076 >  116 !N  136 ^   156 N  176 !^
     017 !!O  037 !!_  057 /  077 ?  117 !O  137 _   157 O  177 !_


File: recode.info,  Node: Micros,  Next: Miscellaneous,  Prev: CDC,  Up: Top

Other micro-computer charsets
*****************************

   The `NeXT' charset, which used to be especially provided in releases
of `recode' before 3.5, has been integrated since as one RFC 1345 table.

* Menu:

* Apple-Mac::           Apple's Macintosh code
* AtariST::             Atari ST code


File: recode.info,  Node: Apple-Mac,  Next: AtariST,  Prev: Micros,  Up: Micros

Apple's Macintosh code
======================

   This charset is available in `recode' under the name `Apple-Mac'.
The shortest way of specifying it in `recode' is `ap'.

   The charset is aimed towards a Macintosh micro-computer from Apple.
This is an eight bit code.  The file is the data fork only.  This
charset is fairly old in `recode', its tables were produced a long
while ago by mere inspection of a printed chart of the Macintosh codes
and glyph.

   It has `CR' as its implied surface.  This means that, if the original
end of lines have to be preserved while going out of `Apple-Mac', they
should currently be added back through the usage of a surface on the
other charset, or better, just never removed.  Here are examples for
both cases:

     recode ap..l2/cr < INPUT > OUTPUT
     recode ap/..l2 < INPUT > OUTPUT

   RFC 1345 brings into `recode' 2 other Macintosh charsets.  You can
discover them by using `grep' over the output of `recode -l':

     recode -l | grep -i mac

Charsets `macintosh' and `macintosh_ce', as well as their aliases `mac'
and `macce' also have `CR' as their implied surface.

   There are a few discrepancies between the `Apple-Mac' charset and
the very similar RFC 1345 charset `macintosh', which have not been
analysed yet, so the charsets are being kept separate for now.  This
might change in the future, and the `Apple-Mac' charset might disappear.
Wizards would be interested in comparing the output of these two
commands:

     recode -vh Apple-Mac..Latin-1
     recode -vh macintosh..Latin-1

The first command use the charset prior to RFC 1345 introduction.  Both
methods give different recodings.  These differences are annoying, the
fuzziness will have to be explained and settle down one day.

   As a side note, some people ask if there is a Macintosh port of the
`recode' program.  I'm not aware of any.  I presume that if the tool
fills a need for Macintosh users, someone will port it one of these
days?


File: recode.info,  Node: AtariST,  Prev: Apple-Mac,  Up: Micros

Atari ST code
=============

   This charset is available in `recode' under the name `AtariST'.

   This is the character set used on the Atari ST/TT/Falcon.  This is
similar to `IBM-PC', but differs in some details: it includes some more
accented characters, the graphic characters are mostly replaced by
Hebrew characters, and there is a true German `sharp s' different from
Greek `beta'.

   About the end-of-line conversions: the canonical end-of-line on the
Atari is `\r\n', but unlike `IBM-PC', the OS makes no difference
between text and binary input/output; it is up to the application how
to interpret the data.  In fact, most of the libraries that come with
compilers can grok both `\r\n' and `\n' as end of lines.  Many of the
users who also have access to Unix systems prefer `\n' to ease porting
Unix utilities.  So, for easing reversibility, `recode' tries to let
`\r' undisturbed through recodings.


File: recode.info,  Node: Miscellaneous,  Next: Surfaces,  Prev: Micros,  Up: Top

Various other charsets
**********************

   Even if these charsets were originally added to `recode' for
handling texts written in French, they find other uses.  We did use them
a lot for writing French diacriticised texts in the past, so `recode'
knows how to handle these particularly well for French texts.

* Menu:

* HTML::                World Wide Web representations
* LaTeX::               LaTeX macro calls
* Texinfo::             GNU project documentation files
* Vietnamese::
* African::             African charsets
* Others::
* Texte::               Easy French conventions
* Mule::                Mule as a multiplexed charset


File: recode.info,  Node: HTML,  Next: LaTeX,  Prev: Miscellaneous,  Up: Miscellaneous

World Wide Web representations
==============================

   This charset is available in `recode' under the name `HTML', with
`h4' as an acceptable alias.

   HTML texts used by World Wide Web often use special sequences,
beginning with an ampersand `&' and ending with a semicolon `;', for
representing characters.  The sequence may itself start with a number
sigh `#' and be followed by digits, so forming a "numeric character
reference", or else be an alphabetic identifier, so forming a
"character entity reference".

   Printable characters from Latin-1 may be used directly in an HTML
text.  However, partly because people have deficient keyboards, partly
because people want to transmit HTML texts over non 8-bit clean
channels while not using MIME, it is common (yet debatable) to use
character entity references even for Latin-1 characters, when they fall
outside ASCII (that is, when they have the 8th bit set).

   When you recode from another charset to `HTML', beware that all
occurrences of double quotes, ampersands, and left or right angle
brackets are translated into special sequences.  However, in practice,
people often use ampersands and angle brackets in the other charset for
introducing HTML commands, compromising it: it is not pure HTML, not it
is pure other charset.  These particular translations can be rather
inconvenient, they may be specifically inhibited through the command
option `-d' (*note Mixed::).

   Codes not having a mnemonic entity are output by `recode' using the
`&#NNN;' notation, where NNN is a decimal representation of the UCS
code value.  When there is an entity name for a character, it is always
preferred over a numeric character reference.  ASCII printable
characters are always generated directly.  So is the newline.  While
reading HTML, `recode' supports numeric character reference as alternate
writings, even when written as hexadecimal numbers, as in `&#xfffd'.
This is documented in:

     http://www.w3.org/TR/REC-html40/intro/sgmltut.html#h-3.2.3

   About levels of HTML, François Yergeau <yergeau@alis.com> writes:

   * HTML 1.0 was never really documented.

   * HTML 2.0 entities are listed in RFC 1866.  Basically, there is an
     entity for each _alphabetical_ character in the right part of
     ISO 8859-1.  In addition, there are four entities for
     syntax-significant ASCII characters: `&amp;', `&gt;', `&lt;' and
     `&quot;'.

   * RFC 2070 (HTML-i18n) added entities to cover the whole right part
     of ISO 8859-1.  The list is conveniently accessible at
     `http://www.alis.com:8085/ietf/html/html-latin1.sgml'.  In
     addition, four i18n-related entities were added: `&zwnj;'
     (`&#8204;'), `&zwj;' (`&#8205;'), `&lrm;' (`&#8206') and `&rlm;'
     (`&#8207;').

   * HTML 3.2 (http://www.w3.org/TR/REC-html32.html) took up the full
     Latin-1 list but not the i18n-related entities from RFC 2070.

   * HTML 4.0 (http://www.w3.org/TR/REC-html40/) has the whole Latin-1
     list, a set of entities for symbols, mathematical symbols, and
     Greek letters, and another set for markup-significant and
     internationalization characters comprising the 4 ASCII entities,
     the 4 i18n-related from RFC 2070 plus some more.

   When `recode' translates to HTML, the translation occurs according
to `http://www.w3.org/TR/REC-html40/sgml/entities.html'.  It is also
assumed that RFC 1866 has an equivalent contents.  When translating
_from_ HTML, `recode' accepts some alternative special sequences, to be
forgiving when files use older HTML tables.

   The `recode' program can be used to _normalise_ an HTML file using
oldish conventions.  For example, it accepts `&AE;', as this once was a
valid writing, somewhere.  However, it should always produce `&AElig;'
instead of `&AE;'.  Yet, this is not completely true.  If one does:

     recode h3..h3 < INPUT

the operation will be optimised into a mere copy, and you can get `&AE;'
this way, if you had some in your input file.  But if you explicitly
defeat the optimisation, like this maybe:

     recode h3..u2,u2..h3 < INPUT

then `&AE;' should be normalised into `&AElig;' by the operation.


File: recode.info,  Node: LaTeX,  Next: Texinfo,  Prev: HTML,  Up: Miscellaneous

LaTeX macro calls
=================

   This charset is available in `recode' under the name `LaTeX' and has
`ltex' as an alias.  It is used for ASCII files coded to be read by
LaTeX or, in certain cases, by TeX.

   Whenever you recode from another charset to `LaTeX', beware that all
occurrences of backslashes `\' are translated into the string
`\backslash{}'.  However, in practice, people often use backslashes in
the other charset for introducing TeX commands, compromising it: it is
not pure TeX, nor it is pure other charset.  This translation of
backslashes into `\backslash{}' can be rather inconvenient, it may be
inhibited through the command option `-d' (*note Mixed::).


File: recode.info,  Node: Texinfo,  Next: Vietnamese,  Prev: LaTeX,  Up: Miscellaneous

GNU project documentation files
===============================

   This charset is available in `recode' under the name `Texinfo' and
has `texi' and `ti' for aliases.  It is used by the GNU project for its
documentation.  Texinfo files may be converted into Info files by the
`makeinfo' program and into nice printed manuals by the TeX system.

   Even if `recode' may transform other charsets to Texinfo, it may not
read Texinfo files yet.  In these times, usages are also changing
between versions of Texinfo, and `recode' only partially succeeds in
correctly following these changes.  So, for now, Texinfo support in
`recode' should be considered as work still in progress (!).


File: recode.info,  Node: Vietnamese,  Next: African,  Prev: Texinfo,  Up: Miscellaneous

Vietnamese charsets
===================

   We are currently experimenting the implementation, in `recode', of a
few character sets and transliterated forms to handle the Vietnamese
language.  They are quite briefly summarised, here.

`TCVN'
     The TCVN charset has an incomplete name.  It might be one of the
     three charset `VN1', `VN2' or `VN3'.  Yes `VN2' might be a second
     version of `VISCII'.  To be clarified.

`VISCII'
     This is an 8-bit character set which seems to be rather popular for
     writing Vietnamese.

`VPS'
     This is an 8-bit character set for Vietnamese.  No much reference.

`VIQR'
     The VIQR convention is a 7-bit, `ASCII' transliteration for
     Vietnamese.

`VNI'
     The VNI convention is a 8-bit, `Latin-1' transliteration for
     Vietnamese.

   Still lacking for Vietnamese in `recode', are the charsets `CP1129'
and `CP1258'.


File: recode.info,  Node: African,  Next: Others,  Prev: Vietnamese,  Up: Miscellaneous

African charsets
================

   Some African character sets are available for a few languages, when
these are heavily used in countries where French is also currently
spoken.

   One African charset is usable for Bambara, Ewondo and Fulfude, as
well as for French.  This charset is available in `recode' under the
name `AFRFUL-102-BPI_OCIL'.  Accepted aliases are `bambara', `bra',
`ewondo' and `fulfude'.  Transliterated forms of the same are available
under the name `AFRFUL-103-BPI_OCIL'.  Accepted aliases are
`t-bambara', `t-bra', `t-ewondo' and `t-fulfude'.

   Another African charset is usable for Lingala, Sango and Wolof, as
well as for French.  This charset is available in `recode' under the
name `AFRLIN-104-BPI_OCIL'.  Accepted aliases are `lingala', `lin',
`sango' and `wolof'.  Transliterated forms of the same are available
under the name `AFRLIN-105-BPI_OCIL'.  Accepted aliases are
`t-lingala', `t-lin', `t-sango' and `t-wolof'.

   To ease exchange with `ISO-8859-1', there is a charset conveying
transliterated forms for Latin-1 in a way which is compatible with the
other African charsets in this series.  This charset is available in
`recode' under the name `AFRL1-101-BPI_OCIL'.  Accepted aliases are
`t-fra' and `t-francais'.


File: recode.info,  Node: Others,  Next: Texte,  Prev: African,  Up: Miscellaneous

Cyrillic and other charsets
===========================

   The following Cyrillic charsets are already available in `recode'
through RFC 1345 tables: `CP1251' with aliases `1251', ` ms-cyrl' and
`windows-1251'; `CSN_369103' with aliases `ISO-IR-139' and `KOI8_L2';
`ECMA-cyrillic' with aliases `ECMA-113', `ECMA-113:1986' and
`iso-ir-111', `IBM880' with aliases `880', `CP880' and
`EBCDIC-Cyrillic'; `INIS-cyrillic' with alias `iso-ir-51'; `ISO-8859-5'
with aliases `cyrillic', ` ISO-8859-5:1988' and `iso-ir-144'; `KOI-7';
`KOI-8' with alias `GOST_19768-74'; `KOI8-R'; `KOI8-RU' and finally
`KOI8-U'.

   There seems to remain some confusion in Roman charsets for Cyrillic
languages, and because a few users requested it repeatedly, `recode'
now offers special services in that area.  Consider these charsets as
experimental and debatable, as the extraneous tables describing them are
still a bit fuzzy or non-standard.  Hopefully, in the long run, these
charsets will be covered in Keld Simonsen's works to the satisfaction of
everybody, and this section will merely disappear.

`KEYBCS2'
     This charset is available under the name `KEYBCS2', with
     `Kamenicky' as an accepted alias.

`CORK'
     This charset is available under the name `CORK', with `T1' as an
     accepted alias.

`KOI-8_CS2'
     This charset is available under the name `KOI-8_CS2'.


File: recode.info,  Node: Texte,  Next: Mule,  Prev: Others,  Up: Miscellaneous

Easy French conventions
=======================

   This charset is available in `recode' under the name `Texte' and has
`txte' for an alias.  It is a seven bits code, identical to `ASCII-BS',
save for French diacritics which are noted using a slightly different
convention.

   At text entry time, these conventions provide a little speed up.  At
read time, they slightly improve the readability over a few alternate
ways of coding diacritics.  Of course, it would better to have a
specialised keyboard to make direct eight bits entries and fonts for
immediately displaying eight bit ISO Latin-1 characters.  But not
everybody is so fortunate.  In a few mailing environments, and sadly
enough, it still happens that the eight bit is often willing-fully
destroyed.

   Easy French has been in use in France for a while.  I only slightly
adapted it (the diaeresis option) to make it more comfortable to several
usages in Que'bec originating from Universite' de Montre'al.  In fact,
the main problem for me was not to necessarily to invent Easy French,
but to recognise the "best" convention to use, (best is not being
defined, here) and to try to solve the main pitfalls associated with
the selected convention.  Shortly said, we have:

`e''
     for `e' (and some other vowels) with an acute accent,

`e`'
     for `e' (and some other vowels) with a grave accent,

`e^'
     for `e' (and some other vowels) with a circumflex accent,

`e"'
     for `e' (and some other vowels) with a diaeresis,

`c,'
     for `c' with a cedilla.

There is no attempt at expressing the `ae' and `oe' diphthongs.  French
also uses tildes over `n' and `a', but seldomly, and this is not
represented either.  In some countries, `:' is used instead of `"' to
mark diaeresis.  `recode' supports only one convention per call,
depending on the `-c' option of the `recode' command.  French quotes
(sometimes called "angle quotes") are noted the same way English quotes
are noted in TeX, _id est_ by ```' and `'''.  No effort has been put to
preserve Latin ligatures (`ae', `oe') which are representable in
several other charsets.  So, these ligatures may be lost through Easy
French conventions.

   The convention is prone to losing information, because the diacritic
meaning overloads some characters that already have other uses.  To
alleviate this, some knowledge of the French language is boosted into
the recognition routines.  So, the following subtleties are
systematically obeyed by the various recognisers.

  1. A comma which follows a `c' is interpreted as a cedilla only if it
     is followed by one of the vowels `a', `o' or `u'.

  2. A single quote which follows a `e' does not necessarily means an
     acute accent if it is followed by a single other one.  For example:

    `e''
          will give an `e' with an acute accent.

    `e'''
          will give a simple `e', with a closing quotation mark.

    `e''''
          will give an `e' with an acute accent, followed by a closing
          quotation mark.

     There is a problem induced by this convention if there are English
     quotations with a French text.  In sentences like:

          There's a meeting at Archie's restaurant.

     the single quotes will be mistaken twice for acute accents.  So
     English contractions and suffix possessives could be mangled.

  3. A double quote or colon, depending on `-c' option, which follows a
     vowel is interpreted as diaeresis only if it is followed by
     another letter.  But there are in French several words that _end_
     with a diaeresis, and the `recode' library is aware of them.
     There are words ending in "igue", either feminine words without a
     relative masculine (besaigue" and cigue"), or feminine words with
     a relative masculine(1) (aigue", ambigue", contigue", exigue",
     subaigue" and suraigue").  There are also words not ending in
     "igue", but instead, either ending by "i"(2) (ai", congai", goi",
     hai"kai", inoui", sai", samurai", thai" and tokai"), ending by "e"
     (canoe") or ending by "u"(3) (Esau").

     Just to complete this topic, note that it would be wrong to make a
     rule for all words ending in "igue" as needing a diaerisis, as
     there are counter-examples (becfigue, be`sigue, bigue, bordigue,
     bourdigue, brigue, contre-digue, digue, d'intrigue, fatigue,
     figue, garrigue, gigue, igue, intrigue, ligue, prodigue, sarigue
     and zigue).

   ---------- Footnotes ----------

   (1) There are supposed to be seven words in this case.  So, one is
missing.

   (2) Look at one of the following sentences (the second has to be
interpreted with the `-c' option):

     "Ai"e!  Voici le proble`me que j'ai"
     Ai:e!  Voici le proble`me que j'ai:

   There is an ambiguity between an ai", the small animal, and the
indicative future of _avoir_ (first person singular), when followed by
what could be a diaeresis mark.  Hopefully, the case is solved by the
fact that an apostrophe always precedes the verb and almost never the
animal.

   (3) I did not pay attention to proper nouns, but this one showed up
as being fairly evident.


File: recode.info,  Node: Mule,  Prev: Texte,  Up: Miscellaneous

Mule as a multiplexed charset
=============================

   This version of `recode' barely starts supporting multiplexed or
super-charsets, that is, those encoding methods by which a single text
stream may contain a combination of more than one constituent charset.
The only multiplexed charset in `recode' is `Mule', and even then, it
is only very partially implemented: the only correspondence available
is with `Latin-1'.  The author fastly implemented this only because he
needed this for himself.  However, it is intended that Mule support to
become more real in subsequent releases of `recode'.

   Multiplexed charsets are not to be confused with mixed charset texts
(*note Mixed::).  For mixed charset input, the rules allowing to
distinguish which charset is current, at any given place, are kind of
informal, and driven from the semantics of what the file contains.  On
the other side, multiplexed charsets are _designed_ to be interpreted
fairly precisely, and quite independently of any informational context.

   The spelling `Mule' originally stands for `_mul_tilingual
_e_nhancement to GNU Emacs', it is the result of a collective effort
orchestrated by Handa Ken'ichi since 1993.  When `Mule' got rewritten
in the main development stream of GNU Emacs 20, the FSF renamed it
`MULE', meaning `_mul_tilingual _e_nvironment in GNU Emacs'.  Even if
the charset `Mule' is meant to stay internal to GNU Emacs, it sometimes
breaks loose in external files, and as a consequence, a recoding tool
is sometimes needed.  Within Emacs, `Mule' comes with `Leim', which
stands for `_l_ibraries of _e_macs _i_nput _m_ethods'.  One of these
libraries is named `quail'(1).

   ---------- Footnotes ----------

   (1) Usually, quail means quail egg in Japanese, while egg alone is
usually chicken egg.  Both quail egg and chicken egg are popular food
in Japan.  The `quail' input system has been named because it is
smaller that the previous `EGG' system.  As for `EGG', it is the
translation of `TAMAGO'.  This word comes from the Japanese sentence
`_ta_kusan _ma_tasete _go_mennasai', meaning `sorry to have let you
wait so long'.  Of course, the publication of `EGG' has been delayed
many times...  (Story by Takahashi Naoto)


File: recode.info,  Node: Surfaces,  Next: Internals,  Prev: Miscellaneous,  Up: Top

All about surfaces
******************

   The "trivial surface" consists of using a fixed number of bits
(often eight) for each character, the bits together hold the integer
value of the index for the character in its charset table.  There are
many kinds of surfaces, beyond the trivial one, all having the purpose
of increasing selected qualities for the storage or transmission.  For
example, surfaces might increase the resistance to channel limits
(`Base64'), the transmission speed (`gzip'), the information privacy
(`DES'), the conformance to operating system conventions (`CR-LF'), the
blocking into records (`VB'), and surely other things as well(1).  Many
surfaces may be applied to a stream of characters from a charset, the
order of application of surfaces is important, and surfaces should be
removed in the reverse order of their application.

   Even if surfaces may generally be applied to various charsets, some
surfaces were specifically designed for a particular charset, and would
not make much sense if applied to other charsets.  In such cases, these
conceptual surfaces have been implemented as `recode' charsets, instead
of as surfaces.  This choice yields to cleaner syntax and usage.  *Note
Universal::.

   Surfaces are implemented within `recode' as special charsets which
may only transform to or from the `data' or `tree' special charsets.
Clever users may use this knowledge for writing surface names in
requests exactly as if they were pure charsets, when the only need is
to change surfaces without any kind of recoding between real charsets.
In such contexts, either `data' or `tree' may also be used as if it
were some kind of generic, anonymous charset: the request
`data..SURFACE' merely adds the given SURFACE, while the request
`SURFACE..data' removes it.

   The `recode' library distinguishes between mere data surfaces, and
structural surfaces, also called tree surfaces for short.  Structural
surfaces might allow, in the long run, transformations between a few
specialised representations of structural information like MIME parts,
Perl or Python initialisers, LISP S-expressions, XML, Emacs outlines,
etc.

   We are still experimenting with surfaces in `recode'.  The concept
opens the doors to many avenues; it is not clear yet which ones are
worth pursuing, and which should be abandoned.  In particular,
implementation of structural surfaces is barely starting, there is not
even a commitment that tree surfaces will stay in `recode', if they do
prove to be more cumbersome than useful.  This chapter presents all
surfaces currently available.

* Menu:

* Permutations::        Permuting groups of bytes
* End lines::           Representation for end of lines
* MIME::                MIME contents encodings
* Dump::                Interpreted character dumps
* Test::                Artificial data for testing

   ---------- Footnotes ----------

   (1) These are mere examples to explain the concept, `recode' only
has `Base64' and `CR-LF', actually.


File: recode.info,  Node: Permutations,  Next: End lines,  Prev: Surfaces,  Up: Surfaces

Permuting groups of bytes
=========================

   A permutation is a surface transformation which reorders groups of
eight-bit bytes.  A _21_ permutation exchanges pairs of successive
bytes.  If the text contains an odd number of bytes, the last byte is
merely copied.  An _4321_ permutation inverts the order of quadruples
of bytes.  If the text does not contains a multiple of four bytes, the
remaining bytes are nevertheless permuted as _321_ if there are three
bytes, _21_ if there are two bytes, or merely copied otherwise.

`21'
     This surface is available in `recode' under the name
     `21-Permutation' and has `swabytes' for an alias.

`4321'
     This surface is available in `recode' under the name
     `4321-Permutation'.


File: recode.info,  Node: End lines,  Next: MIME,  Prev: Permutations,  Up: Surfaces

Representation for end of lines
===============================

   The same charset might slightly differ, from one system to another,
for the single fact that end of lines are not represented identically
on all systems.  The representation for an end of line within `recode'
is the `ASCII' or `UCS' code with value 10, or `LF'.  Other conventions
for representing end of lines are available through surfaces.

`CR'
     This convention is popular on Apple's Macintosh machines.  When
     this surface is applied, each line is terminated by `CR', which has
     `ASCII' value 13.  Unless the library is operating in strict mode,
     adding or removing the surface will in fact _exchange_ `CR' and
     `LF', for better reversibility.  However, in strict mode, the
     exchange does not happen, any `CR' will be copied verbatim while
     applying the surface, and any `LF' will be copied verbatim while
     removing it.

     This surface is available in `recode' under the name `CR', it does
     not have any aliases.  This is the implied surface for the Apple
     Macintosh related charsets.

`CR-LF'
     This convention is popular on Microsoft systems running on IBM PCs
     and compatible.  When this surface is applied, each line is
     terminated by a sequence of two characters: one `CR' followed by
     one `LF', in that order.

     For compatibility with oldish MS-DOS systems, removing a `CR-LF'
     surface will discard the first encountered `C-z', which has
     `ASCII' value 26, and everything following it in the text.  Adding
     this surface will not, however, append a `C-z' to the result.

     This surface is available in `recode' under the name `CR-LF' and
     has `cl' for an alias.  This is the implied surface for the IBM or
     Microsoft related charsets or code pages.

   Some other charsets might have their own representation for an end of
line, which is different from `LF'.  For example, this is the case of
various `EBCDIC' charsets, or `Icon-QNX'.  The recoding of end of lines
is intimately tied into such charsets, it is not available separately
as surfaces.


File: recode.info,  Node: MIME,  Next: Dump,  Prev: End lines,  Up: Surfaces

MIME contents encodings
=======================

   RFC 2045 defines two 7-bit surfaces, meant to prepare 8-bit messages
for transmission.  Base64 is especially usable for binary entities,
while Quoted-Printable is especially usable for text entities, in those
case the lower 128 characters of the underlying charset coincide with
ASCII.

`Base64'
     This surface is available in `recode' under the name `Base64',
     with `b64' and `64' as acceptable aliases.

`Quoted-Printable'
     This surface is available in `recode' under the name
     `Quoted-Printable', with `quote-printable' and `QP' as acceptable
     aliases.

   Note that `UTF-7', which may be also considered as a MIME surface,
is provided as a genuine charset instead, as it necessary relates to
`UCS-2' and nothing else.  *Note UTF-7::.

   A little historical note, also showing the three levels of
acceptance of Internet standards.  MIME changed from a "Proposed
Standard" (RFC 1341-1344, 1992) to a "Draft Standard" (RFC 1521-1523)
in 1993, and was _recycled_ as a "Draft Standard" in 1996-11.  It is
not yet a "Full Standard".


File: recode.info,  Node: Dump,  Next: Test,  Prev: MIME,  Up: Surfaces

Interpreted character dumps
===========================

   Dumps are surfaces meant to express, in ways which are a bit more
readable, the bit patterns used to represent characters.  They allow
the inspection or debugging of character streams, but also, they may
assist a bit the production of C source code which, once compiled,
would hold in memory a copy of the original coding.  However, `recode'
does not attempt, in any way, to produce complete C source files in
dumps.  User hand editing or `Makefile' trickery is still needed for
adding missing lines.  Dumps may be given in decimal, hexadecimal and
octal, and be based over chunks of either one, two or four eight-bit
bytes.  Formatting has been chosen to respect the C language syntax for
number constants, with commas and newlines inserted appropriately.

   However, when dumping two or four byte chunks, the last chunk may be
incomplete.  This is observable through the usage of narrower expression
for that last chunk only.  Such a shorter chunk would not be compiled
properly within a C initialiser, as all members of an array share a
single type, and so, have identical sizes.

`Octal-1'
     This surface corresponds to an octal expression of each input byte.

     It is available in `recode' under the name `Octal-1', with `o1'
     and `o' as acceptable aliases.

`Octal-2'
     This surface corresponds to an octal expression of each pair of
     input bytes, except for the last pair, which may be short.

     It is available in `recode' under the name `Octal-2' and has `o2'
     for an alias.

`Octal-4'
     This surface corresponds to an octal expression of each quadruple
     of input bytes, except for the last quadruple, which may be short.

     It is available in `recode' under the name `Octal-4' and has `o4'
     for an alias.

`Decimal-1'
     This surface corresponds to an decimal expression of each input
     byte.

     It is available in `recode' under the name `Decimal-1', with `d1'
     and `d' as acceptable aliases.

`Decimal-2'
     This surface corresponds to an decimal expression of each pair of
     input bytes, except for the last pair, which may be short.

     It is available in `recode' under the name `Decimal-2' and has
     `d2' for an alias.

`Decimal-4'
     This surface corresponds to an decimal expression of each
     quadruple of input bytes, except for the last quadruple, which may
     be short.

     It is available in `recode' under the name `Decimal-4' and has
     `d4' for an alias.

`Hexadecimal-1'
     This surface corresponds to an hexadecimal expression of each
     input byte.

     It is available in `recode' under the name `Hexadecimal-1', with
     `x1' and `x' as acceptable aliases.

`Hexadecimal-2'
     This surface corresponds to an hexadecimal expression of each pair
     of input bytes, except for the last pair, which may be short.

     It is available in `recode' under the name `Hexadecimal-2', with
     `x2' for an alias.

`Hexadecimal-4'
     This surface corresponds to an hexadecimal expression of each
     quadruple of input bytes, except for the last quadruple, which may
     be short.

     It is available in `recode' under the name `Hexadecimal-4', with
     `x4' for an alias.

   When removing a dump surface, that is, when reading a dump results
back into a sequence of bytes, the narrower expression for a short last
chunk is recognised, so dumping is a fully reversible operation.
However, in case you want to produce dumps by other means than through
`recode', beware that for decimal dumps, the library has to rely on the
number of spaces to establish the original byte size of the chunk.

   Although the library might report reversibility errors, removing a
dump surface is a rather forgiving process: one may mix bases, group a
variable number of data per source line, or use shorter chunks in
places other than at the far end.  Also, source lines not beginning
with a number are skipped.  So, `recode' should often be able to read a
whole C header file, wrapping the results of a previous dump, and
regenerate the original byte string.

